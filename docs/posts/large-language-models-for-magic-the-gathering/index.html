<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Large Language Models for Magic: the Gathering | Jake Boggs</title>
<meta name=keywords content><meta name=description content="Magic: The Gathering (MTG) has always fascinated me with its complexity and strategic depth, thanks to its extensive rulebook and vast array of unique cards. Despite the game&rsquo;s popularity, AI systems specifically designed for MTG have been few and far between, often falling short due to their inability to accurately interpret the intricate rules and interactions between cards. This blog post chronicles my recent endeavor to bridge this gap with large language models (LLMs) by creating a specialized dataset and evaluation metric to improve AI performance in MTG-related tasks."><meta name=author content="Jake Boggs"><link rel=canonical href=https://boggs.tech/posts/large-language-models-for-magic-the-gathering/><link crossorigin=anonymous href=/assets/css/stylesheet.css rel="preload stylesheet" as=style><link rel=icon href=https://boggs.tech/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://boggs.tech/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://boggs.tech/favicon-32x32.png><link rel=apple-touch-icon href=https://boggs.tech/apple-touch-icon.png><link rel=mask-icon href=https://boggs.tech/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://boggs.tech/posts/large-language-models-for-magic-the-gathering/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Large Language Models for Magic: the Gathering"><meta property="og:description" content="Magic: The Gathering (MTG) has always fascinated me with its complexity and strategic depth, thanks to its extensive rulebook and vast array of unique cards. Despite the game&rsquo;s popularity, AI systems specifically designed for MTG have been few and far between, often falling short due to their inability to accurately interpret the intricate rules and interactions between cards. This blog post chronicles my recent endeavor to bridge this gap with large language models (LLMs) by creating a specialized dataset and evaluation metric to improve AI performance in MTG-related tasks."><meta property="og:type" content="article"><meta property="og:url" content="https://boggs.tech/posts/large-language-models-for-magic-the-gathering/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-05-24T23:39:24-04:00"><meta property="article:modified_time" content="2024-05-24T23:39:24-04:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="Large Language Models for Magic: the Gathering"><meta name=twitter:description content="Magic: The Gathering (MTG) has always fascinated me with its complexity and strategic depth, thanks to its extensive rulebook and vast array of unique cards. Despite the game&rsquo;s popularity, AI systems specifically designed for MTG have been few and far between, often falling short due to their inability to accurately interpret the intricate rules and interactions between cards. This blog post chronicles my recent endeavor to bridge this gap with large language models (LLMs) by creating a specialized dataset and evaluation metric to improve AI performance in MTG-related tasks."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://boggs.tech/posts/"},{"@type":"ListItem","position":2,"name":"Large Language Models for Magic: the Gathering","item":"https://boggs.tech/posts/large-language-models-for-magic-the-gathering/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Large Language Models for Magic: the Gathering","name":"Large Language Models for Magic: the Gathering","description":"Magic: The Gathering (MTG) has always fascinated me with its complexity and strategic depth, thanks to its extensive rulebook and vast array of unique cards. Despite the game\u0026rsquo;s popularity, AI systems specifically designed for MTG have been few and far between, often falling short due to their inability to accurately interpret the intricate rules and interactions between cards. This blog post chronicles my recent endeavor to bridge this gap with large language models (LLMs) by creating a specialized dataset and evaluation metric to improve AI performance in MTG-related tasks.","keywords":[],"articleBody":"Magic: The Gathering (MTG) has always fascinated me with its complexity and strategic depth, thanks to its extensive rulebook and vast array of unique cards. Despite the game’s popularity, AI systems specifically designed for MTG have been few and far between, often falling short due to their inability to accurately interpret the intricate rules and interactions between cards. This blog post chronicles my recent endeavor to bridge this gap with large language models (LLMs) by creating a specialized dataset and evaluation metric to improve AI performance in MTG-related tasks.\nThe Challenge of MTG for AI MTG presents two primary challenges for players: deck construction and in-game decision-making. With over 27,000 unique cards and a rulebook nearing 300 pages, understanding card interactions and making optimal plays can be daunting. Current AI models often struggle with these aspects, leading to frequent hallucinations and misunderstandings.\nCustom Dataset and MTG-Eval Metric To address these challenges, I created a custom dataset of MTG-related question-answer pairs, along with an evaluation metric named MTG-Eval. This dataset aims to train and assess language models on their understanding of MTG rules and card interactions. The dataset is divided into three categories:\nCard Descriptions: Questions like “What does card X do?” with answers formatted to mimic card rules text. This helps the model reduce hallucinations by familiarizing it with the text of each card.\nRules Questions: Derived from rulings by the MTG Rules Committee, these questions clarify niche interactions and game scenarios. The official rulings serve as ground-truth answers.\nCard Interactions: Involves questions about combos and card synergies, such as “What is a combo with card X?” or “How can I achieve Y?” The data for this category comes from Commander Spellbook, a comprehensive MTG combo database.\nMethodology Data Generation Data from MTGJSON and Commander Spellbook was used to generate over 80,000 question-answer pairs. The generation process involved using ChatGPT 3.5 to reformat existing data into conversational questions and answers. This synthetic dataset covers a wide range of possible game states and interactions, providing a robust foundation for training.\nTraining Process I fine-tuned Llama 3 8B Instruct, an open-source conversational LLM from Meta, using the custom dataset. The training employed QLoRA to minimize computational requirements, with hyperparameters r=64 and alpha=32 over 75 steps.\nEvaluation I evaluated the model’s performance using a subset of the dataset reserved for testing. Both the base and fine-tuned models were assessed on their ability to answer questions from the card interactions and rules categories, which require deeper comprehension. I used GPT-4 to score the answers on a scale of 1-5, providing consistent and efficient evaluations.\nResults and Impact The fine-tuned model demonstrated a 10.5% improvement over the base model, with an average score increase from 1.62 to 1.79. This indicates a moderate improvement in the model’s understanding of MTG rules and interactions, but both models still have tremendous room to learn.\nFuture Directions Future research could explore the addition of custom tokens for special game symbols like mana and tapping, which are underrepresented in pre-training data and maybe not be appropriately tokenized. Additionally, expanding the dataset to include more diverse game scenarios and interactions could further refine the model’s capabilities.\nConclusion This project showcases the potential of LLMs to enhance the MTG playing experience and the challenges that still need to be overcome to get there. I hope other people will find this dataset useful for training future models and build off my work. There’s certainly much more that could be done and I can’t wait for the day when AI systems can build good decks with my janky pet cards.\nAcknowledgments Thanks to the team at Commander Spellbook for generously sharing their dataset, without which this project would not have been possible. All generated data is unofficial Fan Content permitted under the Fan Content Policy. Not approved/endorsed by Wizards. Portions of the materials used are property of Wizards of the Coast. ©Wizards of the Coast LLC.\nFor more details and access to the dataset and model, visit the following links:\nMTG-Eval Dataset Fine-Tuned Model Training Code on GitHub ","wordCount":"674","inLanguage":"en","datePublished":"2024-05-24T23:39:24-04:00","dateModified":"2024-05-24T23:39:24-04:00","author":{"@type":"Person","name":"Jake Boggs"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://boggs.tech/posts/large-language-models-for-magic-the-gathering/"},"publisher":{"@type":"Organization","name":"Jake Boggs","logo":{"@type":"ImageObject","url":"https://boggs.tech/favicon.ico"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://boggs.tech/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://boggs.tech/startups title=Startups><span>Startups</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class="post-title entry-hint-parent">Large Language Models for Magic: the Gathering</h1><div class=post-meta><span title='2024-05-24 23:39:24 -0400 EDT'>May 24, 2024</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;674 words&nbsp;·&nbsp;Jake Boggs</div></header><div class=post-content><p>Magic: The Gathering (MTG) has always fascinated me with its complexity and strategic depth, thanks to its extensive rulebook and vast array of unique cards. Despite the game&rsquo;s popularity, AI systems specifically designed for MTG have been few and far between, often falling short due to their inability to accurately interpret the intricate rules and interactions between cards. This blog post chronicles my recent endeavor to bridge this gap with large language models (LLMs) by creating a specialized dataset and evaluation metric to improve AI performance in MTG-related tasks.</p><h2 id=the-challenge-of-mtg-for-ai>The Challenge of MTG for AI<a hidden class=anchor aria-hidden=true href=#the-challenge-of-mtg-for-ai>#</a></h2><p>MTG presents two primary challenges for players: deck construction and in-game decision-making. With over 27,000 unique cards and a rulebook nearing 300 pages, understanding card interactions and making optimal plays can be daunting. Current AI models often struggle with these aspects, leading to frequent hallucinations and misunderstandings.</p><h2 id=custom-dataset-and-mtg-eval-metric>Custom Dataset and MTG-Eval Metric<a hidden class=anchor aria-hidden=true href=#custom-dataset-and-mtg-eval-metric>#</a></h2><p>To address these challenges, I created a custom dataset of MTG-related question-answer pairs, along with an evaluation metric named MTG-Eval. This dataset aims to train and assess language models on their understanding of MTG rules and card interactions. The dataset is divided into three categories:</p><ol><li><p><strong>Card Descriptions</strong>: Questions like &ldquo;What does card X do?&rdquo; with answers formatted to mimic card rules text. This helps the model reduce hallucinations by familiarizing it with the text of each card.</p></li><li><p><strong>Rules Questions</strong>: Derived from rulings by the MTG Rules Committee, these questions clarify niche interactions and game scenarios. The official rulings serve as ground-truth answers.</p></li><li><p><strong>Card Interactions</strong>: Involves questions about combos and card synergies, such as &ldquo;What is a combo with card X?&rdquo; or &ldquo;How can I achieve Y?&rdquo; The data for this category comes from <a href=https://commanderspellbook.com/>Commander Spellbook</a>, a comprehensive MTG combo database.</p></li></ol><h2 id=methodology>Methodology<a hidden class=anchor aria-hidden=true href=#methodology>#</a></h2><h3 id=data-generation>Data Generation<a hidden class=anchor aria-hidden=true href=#data-generation>#</a></h3><p>Data from <a href=https://mtgjson.com/>MTGJSON</a> and Commander Spellbook was used to generate over 80,000 question-answer pairs. The generation process involved using ChatGPT 3.5 to reformat existing data into conversational questions and answers. This synthetic dataset covers a wide range of possible game states and interactions, providing a robust foundation for training.</p><h3 id=training-process>Training Process<a hidden class=anchor aria-hidden=true href=#training-process>#</a></h3><p>I fine-tuned Llama 3 8B Instruct, an open-source conversational LLM from Meta, using the custom dataset. The training employed QLoRA to minimize computational requirements, with hyperparameters r=64 and alpha=32 over 75 steps.</p><h2 id=evaluation>Evaluation<a hidden class=anchor aria-hidden=true href=#evaluation>#</a></h2><p>I evaluated the model&rsquo;s performance using a subset of the dataset reserved for testing. Both the base and fine-tuned models were assessed on their ability to answer questions from the card interactions and rules categories, which require deeper comprehension. I used GPT-4 to score the answers on a scale of 1-5, providing consistent and efficient evaluations.</p><h2 id=results-and-impact>Results and Impact<a hidden class=anchor aria-hidden=true href=#results-and-impact>#</a></h2><p>The fine-tuned model demonstrated a 10.5% improvement over the base model, with an average score increase from 1.62 to 1.79. This indicates a moderate improvement in the model&rsquo;s understanding of MTG rules and interactions, but both models still have tremendous room to learn.</p><h2 id=future-directions>Future Directions<a hidden class=anchor aria-hidden=true href=#future-directions>#</a></h2><p>Future research could explore the addition of custom tokens for special game symbols like mana and tapping, which are underrepresented in pre-training data and maybe not be appropriately tokenized. Additionally, expanding the dataset to include more diverse game scenarios and interactions could further refine the model&rsquo;s capabilities.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>This project showcases the potential of LLMs to enhance the MTG playing experience and the challenges that still need to be overcome to get there. I hope other people will find this dataset useful for training future models and build off my work. There&rsquo;s certainly much more that could be done and I can&rsquo;t wait for the day when AI systems can build good decks with my janky pet cards.</p><h2 id=acknowledgments>Acknowledgments<a hidden class=anchor aria-hidden=true href=#acknowledgments>#</a></h2><p>Thanks to the team at Commander Spellbook for generously sharing their dataset, without which this project would not have been possible. All generated data is unofficial Fan Content permitted under the Fan Content Policy. Not approved/endorsed by Wizards. Portions of the materials used are property of Wizards of the Coast. ©Wizards of the Coast LLC.</p><p>For more details and access to the dataset and model, visit the following links:</p><ul><li><a href=https://huggingface.co/datasets/jakeboggs/MTG-Eval>MTG-Eval Dataset</a></li><li><a href=https://huggingface.co/jakeboggs/MTG-Llama>Fine-Tuned Model</a></li><li><a href=https://github.com/JakeBoggs/Large-Language-Models-for-Magic-the-Gathering>Training Code on GitHub</a></li></ul></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://boggs.tech/>Jake Boggs</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>