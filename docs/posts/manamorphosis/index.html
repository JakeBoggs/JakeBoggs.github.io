<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content><meta name=author content="Jake Boggs"><title>Introducing Manamorphosis: A Diffusion Model for MTG Deck Generation | Jake Boggs</title><link rel=stylesheet href=/css/main.min.css><link rel=icon href=/favicon.png><link rel=canonical href=https://boggs.tech/posts/manamorphosis/></head><body><header><div class=container><a href=https://boggs.tech/ class=site-title>Jake Boggs</a><nav><a href=/about>About me</a><a href=/startups>Startups</a></nav></div></header><main><div class=container><article><h1>Introducing Manamorphosis: A Diffusion Model for MTG Deck Generation</h1><div class=article-meta><span>May 5, 2025</span>
<span>3144 words</span>
<span>15 min read</span></div><div class=article-content><p>This post details <strong>Manamorphosis</strong>, a first-of-its-kind diffusion model developed to complete Magic: The Gathering decklists. It takes a set of known cards and fills in the rest to form a 60-card main deck. Subsequently, using the completed main deck as context, it can complete a 15-card sideboard. The core generative mechanism is based on Denoising Diffusion Probabilistic Models (DDPMs), the same family of models powering many image generation systems like Stable Diffusion and Midjourney, but adapted here to produce sets of cards. I&rsquo;m exciting to share this model, as I believe it is the state-of-the-art (and only) AI model trained specifically for decklist generation.</p><p>The complete code is <a href=https://github.com/JakeBoggs/Manamorphosis>available on GitHub</a> if you&rsquo;d like to run it yourself or see the full implementation.</p><h2 id=demo-video>Demo Video</h2><video width=100% controls>
<source src=/videos/manamorphosis.mp4 type=video/mp4>Your browser does not support the video tag.</video><h2 id=card-representation-doc2vec-embeddings>Card Representation: Doc2Vec Embeddings</h2><p>Card identity is represented by 128-dimensional vectors. These embeddings are generated by training a Doc2Vec model on preprocessed text data for each card obtained from <a href=https://mtgjson.com/downloads/all-files/>MTGJSON&rsquo;s AtomicCards.json</a>. This captures semantic relationships based on card text. Much like how modern RAG engines use embeddings to understand the meaning behind search queries and documents, these Doc2Vec embeddings allow the system to grasp the functional similarities between cards based on their descriptions (cost, type, rules text).</p><p>Instead of training the model to directly predict discrete cards from a vocabulary of ~28,000+, Manamorphosis uses pre-trained Doc2Vec embeddings as an intermediate representation. This approach offers several advantages:</p><ol><li><strong>Handling Data Sparsity:</strong> The training dataset (~47,000 decks) contains only a fraction (~5,000) of all legal MTG cards. A model predicting cards directly would struggle to learn meaningful representations or generation logic for the vast majority of cards rarely or never seen during training. The embedding model, trained on <em>all</em> card text, provides a representation for every card.</li><li><strong>Generalization to New/Unseen Cards:</strong> Because the embedding is derived from card text, the system can generate an embedding for <em>any</em> card, including newly released ones, without retraining the embedding model (though retraining the diffusion model might improve performance with new metagames). The diffusion model learns to operate on the <em>semantic meaning</em> captured in the 128-dimensional embedding space, rather than being limited to the fixed vocabulary seen during its own training.</li><li><strong>Capturing Semantic Relationships:</strong> Doc2Vec learns vectors where cards with similar functions, costs, types, or textual patterns (e.g., different variations of counterspells, cheap red burn spells, evasive creatures) are closer together in the embedding space. This allows the diffusion model to learn higher-level concepts (&ldquo;needs more removal,&rdquo; &ldquo;add card draw&rdquo;) rather than just memorizing specific card co-occurrences, leading to potentially more robust and contextually relevant deck completions. This focus on semantic similarity is analogous to how embedding-based search engines return results that are conceptually related, not just keyword matches.</li><li><strong>Dimensionality Reduction & Decoupling:</strong> Working with dense 128-dimensional vectors is more computationally manageable for the transformer architecture than using extremely high-dimensional one-hot vectors (one per card). It also decouples the task of understanding card text semantics (Doc2Vec) from the task of generative deck construction (Diffusion Model).</li></ol><p>Before training the Doc2Vec model, a standardized &ldquo;document&rdquo; is created for each card by applying the following tranformations to the MTGJSON data:</p><ul><li><strong>Mana Cost:</strong> Replaced curly braces <code>{}</code> with pipe symbols <code>|</code> (<code>|W|</code>, <code>|U|</code>, etc.) and ensured spacing around symbols (<code>{W}{U}</code> -> <code>|W| |U|</code>). This treats each mana symbol as a distinct token and distinguishes them from mana symbols in the card text.</li><li><strong>Power/Toughness:</strong> Represented as <code>$Power$ #Toughness#</code> (e.g., <code>$2$ #2#</code>). This creates unique tokens for P/T values.</li><li><strong>Card Type:</strong> The supertype (e.g., &ldquo;Creature&rdquo;, &ldquo;Instant&rdquo;) is split into individual tokens surrounded by pipes (<code>|Creature|</code>, <code>|Instant|</code>). Subtypes (e.g., &ldquo;Goblin&rdquo;, &ldquo;Wizard&rdquo;) are kept as single words.</li><li><strong>Rules Text:</strong><ul><li>Card name references replaced with <code>@</code>. This prevents the model from overfitting to specific card names and focuses on the actions/effects.</li><li>Common self-references (&ldquo;this creature&rdquo;, &ldquo;this enchantment&rdquo;, etc.) also replaced with <code>@</code>.</li><li>Line breaks, semicolons replaced with spaces. Colons have spaces added (<code>:</code> -> <code>:</code>).</li><li>Reminder text (within parentheses) is removed using regex (<code>re.sub(reminder_remover, '', ...)</code>).</li><li>Special characters like <code>&</code>, <code>−</code>, <code>—</code>, <code>'</code>, <code>,</code>, <code>.</code>, <code>'</code>, <code>"</code> are handled (replaced or removed).</li><li>Text is converted to lowercase.</li></ul></li><li><strong>Stop Words:</strong> Common English stop words (like &ldquo;the&rdquo;, &ldquo;a&rdquo;, &ldquo;is&rdquo;) are removed using <code>nltk.corpus.stopwords</code> to reduce noise and focus on meaningful terms.</li></ul><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># From train_embedding_model.py (Illustrative snippet)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>get_text</span>(card):
</span></span><span style=display:flex><span>    text <span style=color:#f92672>=</span> <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;manaCost&#39;</span> <span style=color:#f92672>in</span> card:
</span></span><span style=display:flex><span>        text <span style=color:#f92672>+=</span> card[<span style=color:#e6db74>&#39;manaCost&#39;</span>]<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;}{&#39;</span>, <span style=color:#e6db74>&#39;} {&#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;{&#39;</span>, <span style=color:#e6db74>&#39;|&#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;}&#39;</span>, <span style=color:#e6db74>&#39;|&#39;</span>) <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39; &#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;power&#39;</span> <span style=color:#f92672>in</span> card:
</span></span><span style=display:flex><span>        text <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#39;$&#39;</span> <span style=color:#f92672>+</span> card[<span style=color:#e6db74>&#39;power&#39;</span>] <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;$ #&#39;</span> <span style=color:#f92672>+</span> card[<span style=color:#e6db74>&#39;toughness&#39;</span>] <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;# &#39;</span>
</span></span><span style=display:flex><span>    text <span style=color:#f92672>+=</span> <span style=color:#e6db74>&#39; &#39;</span><span style=color:#f92672>.</span>join([<span style=color:#e6db74>&#39;|&#39;</span> <span style=color:#f92672>+</span> word <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39;|&#39;</span> <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> card[<span style=color:#e6db74>&#39;type&#39;</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39; — &#39;</span>)[<span style=color:#ae81ff>0</span>]<span style=color:#f92672>.</span>split()]) <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39; &#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;—&#39;</span> <span style=color:#f92672>in</span> card[<span style=color:#e6db74>&#39;type&#39;</span>]:
</span></span><span style=display:flex><span>        text <span style=color:#f92672>+=</span> card[<span style=color:#e6db74>&#39;type&#39;</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39; — &#39;</span>)[<span style=color:#ae81ff>1</span>] <span style=color:#f92672>+</span> <span style=color:#e6db74>&#39; &#39;</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> <span style=color:#e6db74>&#39;text&#39;</span> <span style=color:#f92672>in</span> card:
</span></span><span style=display:flex><span>        <span style=color:#75715e># ... (Handling basic lands) ...</span>
</span></span><span style=display:flex><span>        processed_text <span style=color:#f92672>=</span> card[<span style=color:#e6db74>&#39;text&#39;</span>]<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;&amp;&#39;</span>, <span style=color:#e6db74>&#39;and&#39;</span>)<span style=color:#f92672>.</span>replace(card[<span style=color:#e6db74>&#39;name&#39;</span>], <span style=color:#e6db74>&#39;@&#39;</span>)<span style=color:#f92672>.</span>replace(card[<span style=color:#e6db74>&#39;name&#39;</span>]<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39;,&#39;</span>)[<span style=color:#ae81ff>0</span>], <span style=color:#e6db74>&#39;@&#39;</span>) <span style=color:#75715e># simplified</span>
</span></span><span style=display:flex><span>        processed_text <span style=color:#f92672>=</span> processed_text<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;this creature&#39;</span>, <span style=color:#e6db74>&#39;@&#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;this enchantment&#39;</span>, <span style=color:#e6db74>&#39;@&#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;this artifact&#39;</span>, <span style=color:#e6db74>&#39;@&#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;this land&#39;</span>, <span style=color:#e6db74>&#39;@&#39;</span>)
</span></span><span style=display:flex><span>        processed_text <span style=color:#f92672>=</span> processed_text<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;</span><span style=color:#ae81ff>\\</span><span style=color:#e6db74>n&#39;</span>, <span style=color:#e6db74>&#39; &#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;;&#39;</span>, <span style=color:#e6db74>&#39; &#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;:&#39;</span>, <span style=color:#e6db74>&#39; :&#39;</span>)<span style=color:#f92672>.</span>replace(<span style=color:#e6db74>&#39;|&#39;</span>, <span style=color:#e6db74>&#39;•&#39;</span>)
</span></span><span style=display:flex><span>        text <span style=color:#f92672>+=</span> processed_text
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    text <span style=color:#f92672>=</span> re<span style=color:#f92672>.</span>sub(reminder_remover, <span style=color:#e6db74>&#39;&#39;</span>, text<span style=color:#f92672>.</span>lower()<span style=color:#f92672>...</span> ) <span style=color:#75715e># Lowercasing, punctuation, etc.</span>
</span></span><span style=display:flex><span>    words <span style=color:#f92672>=</span> [word <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> text<span style=color:#f92672>.</span>split(<span style=color:#e6db74>&#39; &#39;</span>) <span style=color:#66d9ef>if</span> word <span style=color:#f92672>!=</span> <span style=color:#e6db74>&#39;&#39;</span>]
</span></span><span style=display:flex><span>    filtered_words <span style=color:#f92672>=</span> [word <span style=color:#66d9ef>for</span> word <span style=color:#f92672>in</span> words <span style=color:#66d9ef>if</span> word <span style=color:#f92672>not</span> <span style=color:#f92672>in</span> stop_words]
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> <span style=color:#e6db74>&#39; &#39;</span><span style=color:#f92672>.</span>join(filtered_words)
</span></span></code></pre></div><p>After building the dataset, Gensim makes training easy:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Doc2Vec Training</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> Doc2Vec(vector_size<span style=color:#f92672>=</span><span style=color:#ae81ff>128</span>, dm<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, dbow_words<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>, min_count<span style=color:#f92672>=</span><span style=color:#ae81ff>2</span>, epochs<span style=color:#f92672>=</span><span style=color:#ae81ff>200</span>, workers<span style=color:#f92672>=</span>cores, seed<span style=color:#f92672>=</span><span style=color:#ae81ff>42</span>)
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>build_vocab(corpus) <span style=color:#75715e># corpus yields TaggedDocument(processed_text.split(), [card_id])</span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>train(corpus, <span style=color:#f92672>...</span>)
</span></span></code></pre></div><p>A simple linear classifier is also trained to map these embeddings back to unique card indices. This classifier is used during inference to identify the cards corresponding to each denoised embedding vector. The alternative is to perform a cosine similarity search over entire set of possible cards, but this is inefficient.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># From train_embedding_classifier.py</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>class</span> <span style=color:#a6e22e>CardClassifier</span>(nn<span style=color:#f92672>.</span>Module):
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>__init__</span>(self, embedding_dim, num_classes):
</span></span><span style=display:flex><span>        super(CardClassifier, self)<span style=color:#f92672>.</span><span style=color:#a6e22e>__init__</span>()
</span></span><span style=display:flex><span>        self<span style=color:#f92672>.</span>network <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(embedding_dim, num_classes)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>def</span> <span style=color:#a6e22e>forward</span>(self, x):
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>return</span> self<span style=color:#f92672>.</span>network(x)
</span></span></code></pre></div><h2 id=diffusion>Diffusion</h2><ol><li><p><strong>Forward Process (Noise Addition):</strong> Starting with the true deck embeddings <code>x0</code>, Gaussian noise is progressively added over <code>T</code> timesteps (here, <code>T=1000</code>). The noise level at each step is determined by a predefined variance schedule, specifically a cosine schedule (<code>cosine_beta_schedule</code>).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># diffusion_model.py</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>cosine_beta_schedule</span>(T, s<span style=color:#f92672>=</span><span style=color:#ae81ff>0.008</span>):
</span></span><span style=display:flex><span>    steps <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>linspace(<span style=color:#ae81ff>0</span>, T, T <span style=color:#f92672>+</span> <span style=color:#ae81ff>1</span>, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>float64)
</span></span><span style=display:flex><span>    alpha_bar <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cos(((steps <span style=color:#f92672>/</span> T) <span style=color:#f92672>+</span> s) <span style=color:#f92672>/</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>+</span> s) <span style=color:#f92672>*</span> torch<span style=color:#f92672>.</span>pi <span style=color:#f92672>*</span> <span style=color:#ae81ff>0.5</span>) <span style=color:#f92672>**</span> <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>    alpha_bar <span style=color:#f92672>=</span> alpha_bar <span style=color:#f92672>/</span> alpha_bar[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>    betas <span style=color:#f92672>=</span> <span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> (alpha_bar[<span style=color:#ae81ff>1</span>:] <span style=color:#f92672>/</span> alpha_bar[:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> torch<span style=color:#f92672>.</span>clip(betas, <span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>0.999</span>)<span style=color:#f92672>.</span>float()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Within DiffusionTrainer class:</span>
</span></span><span style=display:flex><span>beta <span style=color:#f92672>=</span> cosine_beta_schedule(T)<span style=color:#f92672>.</span>to(device) <span style=color:#75715e># T = TIMESTEPS (e.g., 1000)</span>
</span></span><span style=display:flex><span>alpha <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span> <span style=color:#f92672>-</span> beta
</span></span><span style=display:flex><span>alpha_bar <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cumprod(alpha, dim<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># Precompute terms used in diffusion and sampling:</span>
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>register(<span style=color:#e6db74>&#34;sqrt_alpha_bar&#34;</span>, torch<span style=color:#f92672>.</span>sqrt(alpha_bar))
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>register(<span style=color:#e6db74>&#34;sqrt_one_minus_alpha_bar&#34;</span>, torch<span style=color:#f92672>.</span>sqrt(<span style=color:#ae81ff>1.0</span> <span style=color:#f92672>-</span> alpha_bar))
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>register(<span style=color:#e6db74>&#34;beta&#34;</span>, beta)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>register(<span style=color:#e6db74>&#34;alpha&#34;</span>, alpha)
</span></span><span style=display:flex><span><span style=color:#75715e># ... (other registered buffers)</span>
</span></span></code></pre></div><p>The state <code>x_t</code> at timestep <code>t</code> can be sampled directly using the cumulative product <code>alpha_bar</code>:
<code>x_t = sqrt(alpha_bar_t) * x0 + sqrt(1 - alpha_bar_t) * noise</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># diffusion_model.py: DiffusionTrainer.q_sample</span>
</span></span><span style=display:flex><span><span style=color:#75715e># Note: The actual implementation modifies x_t for known cards</span>
</span></span><span style=display:flex><span><span style=color:#75715e># based on the mask *after* the initial noise addition,</span>
</span></span><span style=display:flex><span><span style=color:#75715e># returning a mix of original x0 and noised x_t.</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>q_sample</span>(self, x0, t, mask):
</span></span><span style=display:flex><span>    mask_expanded <span style=color:#f92672>=</span> mask<span style=color:#f92672>.</span>expand_as(x0)
</span></span><span style=display:flex><span>    sqrt_ab <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_extract(self<span style=color:#f92672>.</span>sqrt_alpha_bar, t, x0<span style=color:#f92672>.</span>shape, x0<span style=color:#f92672>.</span>device)
</span></span><span style=display:flex><span>    sqrt_1mab <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>_extract(self<span style=color:#f92672>.</span>sqrt_one_minus_alpha_bar, t, x0<span style=color:#f92672>.</span>shape, x0<span style=color:#f92672>.</span>device)
</span></span><span style=display:flex><span>    noise <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>randn_like(x0)
</span></span><span style=display:flex><span>    <span style=color:#75715e># Calculate the fully noised version first</span>
</span></span><span style=display:flex><span>    x_t_noised <span style=color:#f92672>=</span> sqrt_ab <span style=color:#f92672>*</span> x0 <span style=color:#f92672>+</span> sqrt_1mab <span style=color:#f92672>*</span> noise
</span></span><span style=display:flex><span>    <span style=color:#75715e># Return original embeddings for known positions, noised for unknown</span>
</span></span><span style=display:flex><span>    x_t_masked <span style=color:#f92672>=</span> mask_expanded <span style=color:#f92672>*</span> x0 <span style=color:#f92672>+</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> mask_expanded) <span style=color:#f92672>*</span> x_t_noised
</span></span><span style=display:flex><span>    <span style=color:#75715e># Returns the masked noisy sample and the *original* noise (for loss)</span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> x_t_masked, noise
</span></span></code></pre></div></li><li><p><strong>Reverse Process (Denoising):</strong> The model learns to predict the noise <code>epsilon</code> added at timestep <code>t</code>. Starting from pure noise <code>x_T</code>, the model iteratively refines the embeddings by predicting the noise <code>epsilon_pred = model(x_t, x0, sb_x_t, t, mask, sb_mask)</code> and estimating <code>x_{t-1}</code> until <code>x0</code>, the original noise-free main deck, is reached. During inference, the actual denoising step involves sampling <code>x_{t-1}</code> by subtracting the predicted noise <code>epsilon_pred</code> from <code>x_t</code>, then adding a smaller amount of noise for the next timestep.</p></li></ol><h2 id=model-architecture>Model Architecture</h2><p>The model uses a transformer-based architecture, the same building block behind Large Language Models like the GPT series and BERT. Manamorphosis lacks positional embeddings, treating decks as unordered sets, which differs from typical NLP or vision transformer usage where sequence order is crucial. It has distinct paths for main deck and sideboard processing. The internal model dimension is <code>model_dim=384</code>, and the embedding dimension is <code>EMB_DIM=128</code>.</p><ol><li><p><strong>Time Embeddings:</strong> Timestep <code>t</code> is encoded using standard sinusoidal embeddings, processed by separate MLPs for main deck and sideboard paths.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># diffusion_model.py</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>sinusoidal_embedding</span>(t: torch<span style=color:#f92672>.</span>Tensor, dim: int <span style=color:#f92672>=</span> EMB_DIM):
</span></span><span style=display:flex><span>    half <span style=color:#f92672>=</span> dim <span style=color:#f92672>//</span> <span style=color:#ae81ff>2</span>
</span></span><span style=display:flex><span>    freqs <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>exp(<span style=color:#f92672>-</span>math<span style=color:#f92672>.</span>log(<span style=color:#ae81ff>10000</span>) <span style=color:#f92672>*</span> torch<span style=color:#f92672>.</span>arange(half, device<span style=color:#f92672>=</span>t<span style=color:#f92672>.</span>device) <span style=color:#f92672>/</span> (half <span style=color:#f92672>-</span> <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>    args <span style=color:#f92672>=</span> t[:, <span style=color:#66d9ef>None</span>] <span style=color:#f92672>*</span> freqs[<span style=color:#66d9ef>None</span>]
</span></span><span style=display:flex><span>    emb <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>cat((args<span style=color:#f92672>.</span>sin(), args<span style=color:#f92672>.</span>cos()), dim<span style=color:#f92672>=-</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>if</span> dim <span style=color:#f92672>%</span> <span style=color:#ae81ff>2</span>:
</span></span><span style=display:flex><span>        emb <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>functional<span style=color:#f92672>.</span>pad(emb, (<span style=color:#ae81ff>0</span>, <span style=color:#ae81ff>1</span>))
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> emb
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.__init__</span>
</span></span><span style=display:flex><span>ff_dim <span style=color:#f92672>=</span> cfg[<span style=color:#e6db74>&#34;dim_feedforward&#34;</span>] <span style=color:#75715e># 3072</span>
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>main_time_mlp <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(EMB_DIM, ff_dim), nn<span style=color:#f92672>.</span>SiLU(), nn<span style=color:#f92672>.</span>Linear(ff_dim, EMB_DIM),
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>sb_time_mlp <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential( <span style=color:#75715e># For Sideboard Decoder path</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(EMB_DIM, ff_dim), nn<span style=color:#f92672>.</span>SiLU(), nn<span style=color:#f92672>.</span>Linear(ff_dim, EMB_DIM),
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li><li><p><strong>Mask Embeddings:</strong> Binary masks (1.0 for known, 0.0 for unknown) are processed by separate MLPs.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.__init__</span>
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>main_mask_mlp <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential(
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>1</span>, EMB_DIM), nn<span style=color:#f92672>.</span>SiLU(), nn<span style=color:#f92672>.</span>Linear(EMB_DIM, EMB_DIM),
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>sb_mask_mlp <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Sequential( <span style=color:#75715e># For Sideboard Decoder path</span>
</span></span><span style=display:flex><span>    nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>1</span>, ff_dim), nn<span style=color:#f92672>.</span>SiLU(), nn<span style=color:#f92672>.</span>Linear(ff_dim, EMB_DIM), <span style=color:#75715e># Note: intermediate dim is ff_dim here</span>
</span></span><span style=display:flex><span>)
</span></span></code></pre></div></li><li><p><strong>Input Processing:</strong> Input embeddings <code>x_t</code> (main) or <code>sb_x_t</code> (sideboard) are combined via addition with their respective time and mask embeddings, then projected to <code>model_dim</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.forward</span>
</span></span><span style=display:flex><span>sin_emb <span style=color:#f92672>=</span> sinusoidal_embedding(t, EMB_DIM) <span style=color:#75715e># Shape: [Batch, EMB_DIM]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Main Deck Input</span>
</span></span><span style=display:flex><span>main_t_emb_flat <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>main_time_mlp(sin_emb) <span style=color:#75715e># Shape: [Batch, EMB_DIM]</span>
</span></span><span style=display:flex><span>main_t_emb <span style=color:#f92672>=</span> main_t_emb_flat[:, <span style=color:#66d9ef>None</span>, :]<span style=color:#f92672>.</span>expand(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, DECK_SIZE, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#75715e># Shape: [Batch, DECK_SIZE, EMB_DIM]</span>
</span></span><span style=display:flex><span>main_mask_emb <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>main_mask_mlp(mask) <span style=color:#75715e># mask shape: [Batch, DECK_SIZE, 1] -&gt; Output: [Batch, DECK_SIZE, EMB_DIM]</span>
</span></span><span style=display:flex><span>h_main <span style=color:#f92672>=</span> x_t <span style=color:#f92672>+</span> main_t_emb <span style=color:#f92672>+</span> main_mask_emb <span style=color:#75715e># x_t shape: [Batch, DECK_SIZE, EMB_DIM]</span>
</span></span><span style=display:flex><span>h_main_proj <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>main_input_proj(h_main) <span style=color:#75715e># Linear(EMB_DIM, model_dim) -&gt; Shape: [Batch, DECK_SIZE, model_dim]</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Sideboard Input</span>
</span></span><span style=display:flex><span>sb_decoder_t_emb_flat <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sb_time_mlp(sin_emb) <span style=color:#75715e># Shape: [Batch, EMB_DIM]</span>
</span></span><span style=display:flex><span>sb_decoder_t_emb <span style=color:#f92672>=</span> sb_decoder_t_emb_flat[:, <span style=color:#66d9ef>None</span>, :]<span style=color:#f92672>.</span>expand(<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>, SIDEBOARD_SIZE, <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>) <span style=color:#75715e># Shape: [Batch, SIDEBOARD_SIZE, EMB_DIM]</span>
</span></span><span style=display:flex><span>sb_decoder_mask_emb <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sb_mask_mlp(sb_mask) <span style=color:#75715e># sb_mask shape: [Batch, SIDEBOARD_SIZE, 1] -&gt; Output: [Batch, SIDEBOARD_SIZE, EMB_DIM]</span>
</span></span><span style=display:flex><span>h_sb <span style=color:#f92672>=</span> sb_x_t <span style=color:#f92672>+</span> sb_decoder_t_emb <span style=color:#f92672>+</span> sb_decoder_mask_emb <span style=color:#75715e># sb_x_t shape: [Batch, SIDEBOARD_SIZE, EMB_DIM]</span>
</span></span><span style=display:flex><span>h_sb_proj <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sb_input_proj(h_sb) <span style=color:#75715e># Linear(EMB_DIM, model_dim) -&gt; Shape: [Batch, SIDEBOARD_SIZE, model_dim]</span>
</span></span></code></pre></div></li><li><p><strong>Main Deck Path (Encoder):</strong> Processes <code>h_main_proj</code> through a standard <code>nn.TransformerEncoder</code> (<code>layers=8</code>, <code>nhead=8</code>). The output is projected back to <code>EMB_DIM</code> to predict main deck noise (<code>main_noise_pred</code>).</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.__init__</span>
</span></span><span style=display:flex><span>main_encoder_layer <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>TransformerEncoderLayer(d_model<span style=color:#f92672>=</span>model_dim, nhead<span style=color:#f92672>=</span>nhead, <span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>main_transformer_encoder <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>TransformerEncoder(main_encoder_layer, num_layers<span style=color:#f92672>=</span>num_layers)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>main_output_proj <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(model_dim, EMB_DIM)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.forward</span>
</span></span><span style=display:flex><span>main_encoded <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>main_transformer_encoder(h_main_proj)
</span></span><span style=display:flex><span>main_noise_pred <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>main_output_proj(main_encoded)
</span></span></code></pre></div></li><li><p><strong>Sideboard Context Path (Encoder):</strong> Processes the <em>original</em> main deck embeddings <code>x0</code> (noise-free) through a separate, shallow transformer encoder to create context (<code>sb_context_encoded</code>). This context is used by the sideboard decoder.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.__init__</span>
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>sb_context_input_proj <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(EMB_DIM, model_dim)
</span></span><span style=display:flex><span>sb_context_encoder_layer <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>TransformerEncoderLayer(d_model<span style=color:#f92672>=</span>model_dim, nhead<span style=color:#f92672>=</span>nhead, <span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>sideboard_context_encoder <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>TransformerEncoder(sb_context_encoder_layer, num_layers<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.forward</span>
</span></span><span style=display:flex><span>h_sb_context <span style=color:#f92672>=</span> x0 <span style=color:#75715e># Original main deck embeddings</span>
</span></span><span style=display:flex><span>h_sb_context_proj <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sb_context_input_proj(h_sb_context)
</span></span><span style=display:flex><span>sb_context_encoded <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sideboard_context_encoder(h_sb_context_proj)
</span></span></code></pre></div></li><li><p><strong>Sideboard Path (Decoder):</strong> Processes projected sideboard embeddings <code>h_sb_proj</code> using a transformer decoder, conditioned on <code>sb_context_encoded</code> via cross-attention. The decoder output is passed through another encoder before the final projection back to <code>EMB_DIM</code> to predict sideboard noise (<code>sb_noise_pred</code>). The use of cross-attention to condition the sideboard generation on the main deck context is similar to how text-to-image models condition image generation on a text prompt.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.__init__</span>
</span></span><span style=display:flex><span>sb_decoder_layer <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>TransformerDecoderLayer(d_model<span style=color:#f92672>=</span>model_dim, nhead<span style=color:#f92672>=</span>nhead, <span style=color:#f92672>...</span>)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>sb_transformer_decoder <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>TransformerDecoder(sb_decoder_layer, num_layers<span style=color:#f92672>=</span><span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span><span style=color:#75715e># Uses the same sb_context_encoder_layer definition for the subsequent encoder</span>
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>sb_transformer_output <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>TransformerEncoder(sb_context_encoder_layer, num_layers<span style=color:#f92672>=</span>sb_num_layers)
</span></span><span style=display:flex><span>self<span style=color:#f92672>.</span>sb_output_proj <span style=color:#f92672>=</span> nn<span style=color:#f92672>.</span>Linear(model_dim, EMB_DIM)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Within DiffusionModel.forward</span>
</span></span><span style=display:flex><span>sb_decoded <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sb_transformer_decoder(tgt<span style=color:#f92672>=</span>h_sb_proj, memory<span style=color:#f92672>=</span>sb_context_encoded)
</span></span><span style=display:flex><span>sb_decoded <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sb_transformer_output(sb_decoded)
</span></span><span style=display:flex><span>sb_noise_pred <span style=color:#f92672>=</span> self<span style=color:#f92672>.</span>sb_output_proj(sb_decoded)
</span></span></code></pre></div></li></ol><h2 id=conditioning-masking-strategy>Conditioning: Masking Strategy</h2><p>Conditional generation (deck completion) is handled via masking. Known card embeddings are provided by the user (or determined during training). This mechanism is analogous to providing a starting image and a mask for inpainting in image generation models, or providing a text prompt to guide generation.</p><ul><li><p><strong>Training:</strong> For each training sample (<code>x0_embeddings</code>, <code>x0_indices</code>, etc.), multiple masks (<code>masks_per_deck</code>) are generated dynamically per deck.</p><ul><li>The number of known main deck cards <code>k_main</code> is sampled from partitioned ranges [1, 59] across the generated masks to ensure diverse <code>k</code> values are seen.</li><li>Sideboard <code>k_sb</code> is sampled randomly from [1, 14], with a 50% chance of being forced to 0. This is done so that the model performs well at generating sideboards from scratch, which I expect to be a common use case.</li></ul></li><li><p><strong>Masking Logic:</strong> This function generates a single mask row (shape <code>[deck_size, 1]</code>) for a target <code>k</code>. It identifies unique available card indices in the current deck (<code>current_deck_indices</code>). It samples these unique cards <em>without replacement</em> using weights derived from pre-calculated popularity scores (<code>self.card_popularity</code>), slightly favoring less popular cards (<code>0.5 + score</code>, where score is <code>1.0 - normalized_count</code>). It iterates through these weighted, shuffled unique cards. For each unique card, with 85% probability, it attempts to mask all available copies (up to <code>k</code> remaining); with 15% probability, it masks a random number of available copies (from 1 up to available, limited by <code>k</code> remaining). This process repeats until <code>k</code> positions are marked as known (1.0 in the mask). We typically want to mask all instances of a card to make the task harder, so that the model has to learn what cards go together and not just to add additional copies.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># diffusion_model.py: DiffusionTrainer._create_mask_row (Simplified Pseudocode)</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>def</span> <span style=color:#a6e22e>_create_mask_row</span>(k_target, deck_size, current_deck_indices, popularity_scores):
</span></span><span style=display:flex><span>    mask_row <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>zeros(deck_size, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>    available_indices <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>ones(deck_size, dtype<span style=color:#f92672>=</span>torch<span style=color:#f92672>.</span>bool)
</span></span><span style=display:flex><span>    masked_count <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>while</span> masked_count <span style=color:#f92672>&lt;</span> k_target <span style=color:#f92672>and</span> available_indices<span style=color:#f92672>.</span>any():
</span></span><span style=display:flex><span>        <span style=color:#75715e># 1. Get unique card indices from currently *available* positions</span>
</span></span><span style=display:flex><span>        unique_cards <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>unique(current_deck_indices[available_indices])
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>if</span> <span style=color:#f92672>not</span> unique_cards: <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 2. Calculate sampling weights (favor less popular)</span>
</span></span><span style=display:flex><span>        weights <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>tensor([<span style=color:#ae81ff>0.5</span> <span style=color:#f92672>+</span> popularity_scores<span style=color:#f92672>.</span>get(idx<span style=color:#f92672>.</span>item(), <span style=color:#ae81ff>1.0</span>) <span style=color:#66d9ef>for</span> idx <span style=color:#f92672>in</span> unique_cards])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#75715e># 3. Sample unique cards without replacement based on weights</span>
</span></span><span style=display:flex><span>        perm_indices <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>multinomial(weights, num_samples<span style=color:#f92672>=</span>len(unique_cards), replacement<span style=color:#f92672>=</span><span style=color:#66d9ef>False</span>)
</span></span><span style=display:flex><span>        shuffled_unique_cards <span style=color:#f92672>=</span> unique_cards[perm_indices]
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span> card_idx <span style=color:#f92672>in</span> shuffled_unique_cards:
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> masked_count <span style=color:#f92672>&gt;=</span> k_target: <span style=color:#66d9ef>break</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 4. Find available positions for this specific card_idx</span>
</span></span><span style=display:flex><span>            potential_pos <span style=color:#f92672>=</span> (current_deck_indices <span style=color:#f92672>==</span> card_idx)<span style=color:#f92672>.</span>nonzero(as_tuple<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)[<span style=color:#ae81ff>0</span>]
</span></span><span style=display:flex><span>            available_pos <span style=color:#f92672>=</span> potential_pos[available_indices[potential_pos]] <span style=color:#75715e># Filter by available</span>
</span></span><span style=display:flex><span>            available_count <span style=color:#f92672>=</span> len(available_pos)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> available_count <span style=color:#f92672>==</span> <span style=color:#ae81ff>0</span>: <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            needed <span style=color:#f92672>=</span> k_target <span style=color:#f92672>-</span> masked_count
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 5. Decide how many copies to mask (85% all available, 15% random count)</span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>if</span> random<span style=color:#f92672>.</span>random() <span style=color:#f92672>&lt;</span> <span style=color:#ae81ff>0.85</span>:
</span></span><span style=display:flex><span>                num_to_mask <span style=color:#f92672>=</span> min(available_count, needed)
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>else</span>:
</span></span><span style=display:flex><span>                max_can_mask <span style=color:#f92672>=</span> min(available_count, needed)
</span></span><span style=display:flex><span>                <span style=color:#66d9ef>if</span> max_can_mask <span style=color:#f92672>&lt;=</span> <span style=color:#ae81ff>0</span>: <span style=color:#66d9ef>continue</span>
</span></span><span style=display:flex><span>                num_to_mask <span style=color:#f92672>=</span> random<span style=color:#f92672>.</span>randint(<span style=color:#ae81ff>1</span>, max(<span style=color:#ae81ff>1</span>, max_can_mask))
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#75715e># 6. Select specific positions to mask and update mask_row/available_indices</span>
</span></span><span style=display:flex><span>            indices_to_mask <span style=color:#f92672>=</span> available_pos[torch<span style=color:#f92672>.</span>randperm(available_count)[:num_to_mask]]
</span></span><span style=display:flex><span>            mask_row[indices_to_mask] <span style=color:#f92672>=</span> <span style=color:#ae81ff>1.0</span>
</span></span><span style=display:flex><span>            available_indices[indices_to_mask] <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>            masked_count <span style=color:#f92672>+=</span> num_to_mask
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>return</span> mask_row
</span></span></code></pre></div></li><li><p><strong>Loss Calculation:</strong> The MSE loss is computed only between the predicted noise (<code>main_noise_pred</code>, <code>sb_noise_pred</code>) and the true noise (<code>noise</code>, <code>sb_noise</code> from <code>q_sample</code>) for the <em>unknown</em> (mask value 0.0) card slots. This focuses the model on learning to generate the missing parts.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># diffusion_model.py: DiffusionTrainer.p_losses</span>
</span></span><span style=display:flex><span>main_loss <span style=color:#f92672>=</span> ((noise <span style=color:#f92672>-</span> main_noise_pred) <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> mask<span style=color:#f92672>.</span>expand_as(noise)))<span style=color:#f92672>.</span>pow(<span style=color:#ae81ff>2</span>)<span style=color:#f92672>.</span>mean()
</span></span><span style=display:flex><span>sb_loss <span style=color:#f92672>=</span> ((sb_noise <span style=color:#f92672>-</span> sb_noise_pred) <span style=color:#f92672>*</span> (<span style=color:#ae81ff>1</span> <span style=color:#f92672>-</span> sb_mask<span style=color:#f92672>.</span>expand_as(sb_noise)))<span style=color:#f92672>.</span>pow(<span style=color:#ae81ff>2</span>)<span style=color:#f92672>.</span>mean()
</span></span><span style=display:flex><span>total_loss <span style=color:#f92672>=</span> main_loss <span style=color:#f92672>+</span> sb_loss
</span></span></code></pre></div></li><li><p><strong>Inference:</strong> During the reverse diffusion process (sampling <code>x_{t-1}</code> from <code>x_t</code>), the known card embeddings <code>x0_known</code> (provided by the user) are reapplied at each step to guide the generation towards the desired completion. A common approach (simplified):</p><ol><li>Predict noise: <code>epsilon_pred = model(x_t, x0_context, sb_x_t, t, mask, sb_mask)</code></li><li>Calculate the parameters (mean, variance) of the distribution <code>p(x_{t-1} | x_t)</code> using <code>x_t</code>, <code>t</code>, and <code>epsilon_pred</code> according to the diffusion schedule.</li><li>Sample the potential next state <code>x_{t-1}_sample</code> from this distribution (adding noise if <code>t > 0</code>, otherwise using the mean).</li><li>Re-apply knowns to the sample: <code>x_{t-1}_conditioned = mask * x0_known + (1 - mask) * x_{t-1}_sample</code>.</li><li>Use <code>x_{t-1}_conditioned</code> as the input <code>x_t</code> for the next step (t-2).
The main deck context <code>sb_context_encoded</code> for the sideboard decoder is generated from the <em>final</em> denoised main deck embeddings (<code>x0_main_final</code>).</li></ol></li></ul><h2 id=training>Training</h2><p>The current model was trained using ~47,000 decks scraped from MTGTop8 and is format agnostic, with the training data covering Standard, Modern, Pioneer, Pauper, Legacy, and Vintage. The full model contains ~56 million parameters. Due to its small size, training was feasible on consumer hardware, specifically a single Nvidia 3050 Laptop GPU with 4GB of VRAM, taking roughly 4 days to complete 100 epochs.</p><ul><li><strong>Dataset:</strong> <code>DeckDataset</code> loads decks and filters for exact 60 main deck / 15 sideboard card counts. It converts card names to the pre-trained Doc2Vec embeddings and retrieves corresponding integer indices using the mapping from the linear classifier. Decks with cards missing from embeddings or the classifier map are skipped. It also calculates card popularity scores based on deck frequency for the masking strategy.</li><li><strong>Optimizer:</strong> AdamW with weight decay.</li><li><strong>Objective:</strong> Minimize the combined MSE loss <code>total_loss</code> described above, calculated over <code>masks_per_deck</code> different masks for each deck in the batch.</li><li><strong>Process:</strong> Standard PyTorch training loop: iterates epochs, loads batches via DataLoader, calculates loss using <code>p_losses</code>, performs backpropagation, clips gradients, and updates optimizer. Checkpoints containing model state dict, epoch, and config are saved periodically.</li></ul><h2 id=inference-enforcing-deck-rules-with-iterative-refinement>Inference: Enforcing Deck Rules with Iterative Refinement</h2><p>While the diffusion model learns the underlying patterns of deck construction from the training data, it doesn&rsquo;t inherently guarantee adherence to strict game rules like the 4-copy limit for non-basic cards or format legality during the raw generation process. To address this, the inference functions employ an iterative refinement strategy after the initial denoising pass:</p><ol><li><strong>Initial Generation:</strong> The standard reverse diffusion process is performed once to generate initial embeddings for all unknown card slots, conditioned on any user-provided cards.</li><li><strong>Classification & Rule Check:</strong> The resulting embeddings (both originally known and newly generated) are converted back to card names using the trained linear classifier. The system then checks for violations:<ul><li><strong>4-Copy Limit:</strong> It counts occurrences of each non-basic card name. For sideboard generation, this count considers cards in both the main deck and the current sideboard iteration.</li><li><strong>Format Legality:</strong> Each <em>generated</em> card is checked for legality in the specified format (e.g., &lsquo;Modern&rsquo;, &lsquo;Standard&rsquo;). Basic lands are exempt from this check.</li></ul></li><li><strong>Identify Violations:</strong> The system identifies the specific <em>generated</em> card slots that violate either the 4-copy limit or format legality. User-provided cards are never marked for regeneration.</li><li><strong>Mask Update & Regeneration:</strong> A new mask is created. User-provided cards and <em>valid</em> generated cards from the current iteration are marked as &ldquo;known&rdquo;. Slots corresponding to rule violations are marked as &ldquo;unknown&rdquo;.</li><li><strong>Re-run Diffusion:</strong> The reverse diffusion sampling process is run <em>again</em>, using the updated mask and the embeddings of the known cards (including the valid generated ones) as fixed context. The model only needs to generate new embeddings for the slots marked as unknown due to rule violations.</li><li><strong>Repeat:</strong> Steps 2-5 are repeated up to a fixed number of maximum refinement iterations. This loop continues until no rule violations are found among the generated cards or the iteration limit is reached.</li></ol><p>This refinement loop significantly improves the likelihood of producing legal deck completions by correcting rule violations after the initial generation, leveraging the classifier and external card data to guide the process without needing to bake these complex constraints directly into the diffusion model&rsquo;s training objective. The final deck combines the original user input with the cards generated and through this process.</p><h2 id=final-thoughts>Final Thoughts</h2><p>This was a fun, but time-consuming project (two weeks of me procrastinating before finals). Some day I&rsquo;ll probably train v2 to address some of the many remaining issues, but until then you can keep up with what I&rsquo;m up to on Twitter: <a href=https://x.com/JakeABoggs>@JakeABoggs</a></p></div></article></div></main><footer><div class=container><p>&copy; 2026 Jake Boggs</p></div></footer></body></html>