<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Jake Boggs</title>
    <link>https://boggs.tech/</link>
    <description>Recent content on Jake Boggs</description>
    <generator>Hugo -- 0.154.5</generator>
    <language>en</language>
    <lastBuildDate>Mon, 19 Jan 2026 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://boggs.tech/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Translating Historical Manuscripts with Gemini 3</title>
      <link>https://boggs.tech/posts/translating-manuscripts-with-gemini/</link>
      <pubDate>Mon, 19 Jan 2026 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/translating-manuscripts-with-gemini/</guid>
      <description>&lt;p&gt;I&amp;rsquo;ve spent a lot of time working on document understanding for products like &lt;a href=&#34;https://www.endeavor.ai/order-entry-automation&#34;&gt;automated order entry&lt;/a&gt; and so I&amp;rsquo;m always looking for new ways to evaluate the visual capabilities of LLMs. About a month ago, I stumbled across &lt;a href=&#34;https://generativehistory.substack.com/p/the-sugar-loaf-test-how-an-18th-century&#34;&gt;this post&lt;/a&gt; by Mark Humphries about Gemini 3 Pro&amp;rsquo;s impressive ability to transcribe historical texts. This seemed interesting enough to spend an evening building an app around (and I wanted to impress my girlfriend, who majors in anthropology and is interested in medieval medicine).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scalable Reinforcement Learning with LLMs - Atropos Guide</title>
      <link>https://boggs.tech/posts/atropos-guide-reinforcement-learning-with-llms/</link>
      <pubDate>Fri, 16 May 2025 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/atropos-guide-reinforcement-learning-with-llms/</guid>
      <description>&lt;p&gt;This weekend, I will be in attendance at the &lt;a href=&#34;https://cerebralvalley.ai/e/nous-research-rl-environments-hackathon-9be3062a&#34;&gt;Nous Research â€“ RL Environments Hackathon&lt;/a&gt;, so to prepare I&amp;rsquo;ve been playing around with Atropos, their new RL framework that we will be using for the event. After failing to find any guides online, I decided to write my own.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Update:&lt;/strong&gt; I got 2nd place with VR-CLImax, my implementation of Verified Rewards via Completion Likelihood Improvement, an RL environment for teaching LLMs how to make jokes! You can find the code merged into the &lt;a href=&#34;https://github.com/NousResearch/atropos/tree/main/environments/community/punchline_vrcli&#34;&gt;Atropos repository&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Evaluating Reasoning in LLMs Through MTG Deck Building</title>
      <link>https://boggs.tech/posts/evaluating-llm-reasoning-with-mtg-deck-building/</link>
      <pubDate>Fri, 09 May 2025 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/evaluating-llm-reasoning-with-mtg-deck-building/</guid>
      <description>&lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 18px; font-size: 1.08em; font-weight: 500;&#34;&gt;
  &lt;strong&gt;Update (2026-01-14):&lt;/strong&gt; Gemini 3 Pro, Gemini 3 Flash, GPT 5.2 (medium), Claude Opus 4.5, and Grok 4.1 Fast added.
&lt;/div&gt;
&lt;details style=&#34;margin-bottom: 18px;&#34;&gt;
  &lt;summary style=&#34;cursor: pointer; font-weight: 500;&#34;&gt;View Older Updates&lt;/summary&gt;
  &lt;div style=&#34;padding-top: 10px;&#34;&gt;
    &lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 18px; font-size: 1.08em; font-weight: 500;&#34;&gt;
    &lt;strong&gt;Update (2025-08-08):&lt;/strong&gt; GPT-5, GPT-5 Mini, GPT-5 Nano, GPT-4 Turbo 11-06, and GPT-3.5 Turbo added.
    &lt;/div&gt;
    &lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 18px; font-size: 1.08em; font-weight: 500;&#34;&gt;
      &lt;strong&gt;Update (2025-08-05):&lt;/strong&gt; Kimi K2, GPT OSS 120B (low), and GPT OSS 120B (high) added.
    &lt;/div&gt;
    &lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 18px; font-size: 1.08em; font-weight: 500;&#34;&gt;
      &lt;strong&gt;Update (2025-07-13):&lt;/strong&gt; Grok 4, Grok 3, Gemini 2.5 Flash, Claude Sonnet 4 (thinking), and Command A added.
    &lt;/div&gt;
    &lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 18px; font-size: 1.08em; font-weight: 500;&#34;&gt;
      &lt;strong&gt;Update (2025-06-11):&lt;/strong&gt; o3 (high) added after API cost reduction.
    &lt;/div&gt;
    &lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 18px; font-size: 1.08em; font-weight: 500;&#34;&gt;
      &lt;strong&gt;Update (2025-06-06):&lt;/strong&gt; Deepseek R1 05-28 and Gemini 2.5 Pro 06-05 added.
    &lt;/div&gt;
    &lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 18px; font-size: 1.08em; font-weight: 500;&#34;&gt;
      &lt;strong&gt;Update (2025-05-22):&lt;/strong&gt; Claude Sonnet 4 and Opus 4 added.
    &lt;/div&gt;
    &lt;div style=&#34;background: #e0f7fa; color: #006064; padding: 12px 18px; border-radius: 6px; margin-bottom: 0; font-size: 1.08em; font-weight: 500;&#34;&gt;
      &lt;strong&gt;Update (2025-05-14):&lt;/strong&gt; Human Baseline, Gemini 2.5 Pro 03-25, Gemini 1.5 Flash, Deepseek V3 03-24, Qwen3 30B 3A added.
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/details&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;I have an obsession with applying AI models to my favorite card game, so I&amp;rsquo;ve created ManaBench, a benchmark designed to probe an LLM&amp;rsquo;s capacity for reasoning using the collectible card game Magic: The Gathering (MTG). With its intricate interactions and deep strategy, MTG serves as an ideal micro-world to test an LLM&amp;rsquo;s ability to process contextual information, identify patterns, and make judgments that align with expert human choices. This post provides an overview of the benchmark&amp;rsquo;s construction and the methodology used for evaluation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introducing Manamorphosis: A Diffusion Model for MTG Deck Generation</title>
      <link>https://boggs.tech/posts/manamorphosis/</link>
      <pubDate>Mon, 05 May 2025 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/manamorphosis/</guid>
      <description>&lt;p&gt;This post details &lt;strong&gt;Manamorphosis&lt;/strong&gt;, a first-of-its-kind diffusion model developed to complete Magic: The Gathering decklists. It takes a set of known cards and fills in the rest to form a 60-card main deck. Subsequently, using the completed main deck as context, it can complete a 15-card sideboard. The core generative mechanism is based on Denoising Diffusion Probabilistic Models (DDPMs), the same family of models powering many image generation systems like Stable Diffusion and Midjourney, but adapted here to produce sets of cards. I&amp;rsquo;m exciting to share this model, as I believe it is the state-of-the-art (and only) AI model trained specifically for decklist generation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Gait Analysis for Physical Therapy with YOLOv11</title>
      <link>https://boggs.tech/posts/gait-analysis-physical-therapy-research/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/gait-analysis-physical-therapy-research/</guid>
      <description>&lt;p&gt;Analyzing how people walk using video is common in research and clinical settings, but getting accurate joint angles usually means either expensive equipment or manually annotating frames, which is slow and tedious.&lt;/p&gt;
&lt;p&gt;Over Easter weekend, I built a Python tool to help my mother with her research study analyzing patient videos. It uses YOLOv11-pose for automatic detection and adds an interactive interface for manual adjustments.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Demo&lt;/strong&gt;&lt;/p&gt;
&lt;video width=&#34;100%&#34; controls&gt;
  &lt;source src=&#34;https://boggs.tech/videos/gait-analyzer.mp4&#34; type=&#34;video/mp4&#34;&gt;
  Your browser does not support the video tag.
&lt;/video&gt;
&lt;p&gt;&lt;strong&gt;How it Works&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AccountaBuddy: Your AI Accountability Partner - HackNC 2024</title>
      <link>https://boggs.tech/posts/accountabuddy-hacknc-2024/</link>
      <pubDate>Mon, 04 Nov 2024 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/accountabuddy-hacknc-2024/</guid>
      <description>&lt;p&gt;Check out the project on &lt;strong&gt;&lt;a href=&#34;https://devpost.com/software/nudge-4groy0&#34;&gt;Devpost&lt;/a&gt;&lt;/strong&gt; and view the source code on &lt;strong&gt;&lt;a href=&#34;https://github.com/JakeBoggs/AccountaBuddy-HackNC2024&#34;&gt;GitHub&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;I spent a weekend at HackNC building something to help manage all of my other side projects. What started as &amp;ldquo;Wouldn&amp;rsquo;t it be cool if an AI actually rang you to ask if you&amp;rsquo;d done your work?&amp;rdquo; turned into AccountaBuddy, a lightweight app that does more than fire off push notifications - it actually calls you, celebrates your wins, and helps you problem-solve when progress stalls.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Daily Yap: A Synthetically Generated Conversational Audio Dataset</title>
      <link>https://boggs.tech/posts/synthetic-conversational-audio-generation-daily-yap/</link>
      <pubDate>Sun, 23 Jun 2024 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/synthetic-conversational-audio-generation-daily-yap/</guid>
      <description>&lt;p&gt;Training multimodal models often requires large, high-quality conversational audio datasets, which are scarce at the time of writing.&lt;/p&gt;
&lt;p&gt;Existing conversational audio datasets present several limitations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Content Scope:&lt;/strong&gt; Many datasets focus on assistant-user interactions, lacking the breadth of topics found in general human dialogues.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Audio-Text Alignment:&lt;/strong&gt; Datasets with precise alignment between high-quality audio and accurate transcriptions are uncommon.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speaker Diversity:&lt;/strong&gt; The use of few speakers limits the generalizability of models trained on these datasets.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Scalability:&lt;/strong&gt; Human recording is resource-intensive, hindering the creation of large-scale datasets.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Daily Yap was created to overcome these challenges by providing a synthetically generated conversational audio resource suitable for training real-time conversational audio models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Large Language Models for Magic: the Gathering</title>
      <link>https://boggs.tech/posts/large-language-models-for-magic-the-gathering/</link>
      <pubDate>Fri, 24 May 2024 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/posts/large-language-models-for-magic-the-gathering/</guid>
      <description>&lt;p&gt;Context: this was a project from one of my classes. I dumped the content from my final paper here with some slight tweaks to make a blog post.&lt;/p&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Magic: The Gathering (MTG) has always fascinated me with its complexity and depth, thanks to its extensive rulebook and vast array of unique cards. Despite the game&amp;rsquo;s popularity, AI systems specifically designed for MTG have been few and far between, often falling short due to their inability to accurately interpret the intricate rules and interactions between cards. This blog post chronicles my recent endeavor to bridge this gap with large language models (LLMs) by creating a specialized dataset and evaluation metric to improve AI performance in MTG-related tasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>About me</title>
      <link>https://boggs.tech/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/about/</guid>
      <description>&lt;p&gt;My name is Jake and I have a snake. Currently working full-time at &lt;a href=&#34;https://endeavorai.com/&#34;&gt;Endeavor&lt;/a&gt;. I post here occassionally to share my thoughts and projects that I build.&lt;/p&gt;
&lt;p&gt;Still new to the Bay Area, hit me up if you want to get coffee and chat. Or calzones. I fucking love calzones.&lt;/p&gt;
&lt;div style=&#34;display: flex; flex-wrap: wrap; justify-content: center; gap: 1rem; align-items: flex-start;&#34;&gt;
    &lt;img src=&#34;https://boggs.tech/images/jake.jpg&#34; alt=&#34;Jake&#34; style=&#34;flex: 1 1 200px; max-width: 300px;&#34;&gt;
    &lt;div&gt;
        &lt;img src=&#34;https://boggs.tech/images/snake.jpg&#34; alt=&#34;Snake&#34; style=&#34;flex: 1 1 200px; max-width: 300px;&#34;&gt;
        &lt;div style=&#34;text-align: center;&#34;&gt;
            ^ this guy is Fido
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;
Chances are that if you see me in the wild, I&#39;ll be rocking these:
&lt;div style=&#34;display: flex; flex-wrap: wrap; justify-content: center; gap: 1rem; align-items: flex-start;&#34;&gt;
    &lt;img src=&#34;https://boggs.tech/images/crocs.jpg&#34; alt=&#34;Crocs&#34; style=&#34;flex: 1 1 500px; max-width: 500px;&#34;&gt;
&lt;/div&gt;
&lt;p&gt;I&amp;rsquo;m also skilled at Magic: the Gathering &amp;#x1f60f; (ladies, calm down, one at a time)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Startups</title>
      <link>https://boggs.tech/startups/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://boggs.tech/startups/</guid>
      <description>&lt;p&gt;This page has been up for a while but I recently realized I had never written an explanation of why it exists: I&amp;rsquo;ve always had an irrational fear of getting stuck. Not just in a claustrophobic sense, but also in life. That&amp;rsquo;s partially why I&amp;rsquo;ve been drawn to startups. Every day is something new and you must constantly learn and grow, or die. There are many other more &amp;ldquo;college-essay / job-application appropriate&amp;rdquo; aspects I enjoy too (solving problems, building things, ownership etc are great), but this fear more than anything has been the biggest driver. That, coupled with a strong belief that following conventional wisdom will give you conventional outcomes, motivated me to drop out of college with a semester left when I received an offer from a company I truly believe in. Now that has been said, here are the startups I&amp;rsquo;m most proud to be / have been a part of:&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
